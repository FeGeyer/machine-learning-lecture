{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Different classification algorithms optimize different loss functions. In the previous section we optimized the residual sum of squares. Now we will be looking at the 0-1 loss.\n",
    "\n",
    "\n",
    "__0-1 loss__\n",
    "\n",
    "$$ L_{0,1}(\\hat{Y}, Y) = 1 - \\delta(Y, \\hat{Y}) =    \\begin{cases}\n",
    "                                                    1 & {\\text{if}}\\quad Y \\neq \\hat{Y} \\\\\n",
    "                                                    0 & {\\text{else}} \n",
    "                                                \\end{cases}\n",
    "$$\n",
    "\n",
    "Is used for classification problems as it basically counts the number of missclassifications and works best on discrete values of $Y$.\n",
    "\n",
    "One possible Idea is to try and minimize the 0-1 loss directly.\n",
    "\n",
    "Presume we knew $P(Y| X)$ i.e the probability for the value of the label $Y$ in presence of a data point.\n",
    "Then intuitively the best classifier $f(x) = \\hat{y}$ is the one that minimizes the conditional expected loss.\n",
    "\n",
    "\\begin{align}\n",
    "    E(L_{0,1}(\\hat{y}, y) | x) =& \\sum_{y \\in Y}P(y| x) L_{0,1}(\\hat{y}, y) \\\\\n",
    "            =& \\sum_{y \\in Y}  P(y| x) (1 - \\delta(\\hat{y}, y)) \\\\\n",
    "            =& \\sum_{y \\in Y}  P(y| x) - \\sum_{y \\in Y} \\delta(\\hat{y}, y)) P(y| x) \\\\\n",
    "            =& 1 - \\sum_{y \\in Y} \\delta(f(x), y)) P(y| x) \\\\\n",
    "            =& 1 - P(\\hat{y}| x) \\\\\n",
    "\\end{align}\n",
    "\n",
    "Now if we minimze $L_{0,1}$ we get\n",
    "\n",
    "\\begin{align}\n",
    "f_{*} =& \\arg \\min_f(E(L_{0,1}(f(x), y) ) = \\arg \\min_{\\hat{y}}(E(L_{0,1}(\\hat{y}, y) ) \\\\\n",
    "    =& \\arg \\min_{\\hat{y}} \\left(  1 - P(\\hat{y}| x) \\right) \\\\\n",
    "    =& \\arg \\max_{\\hat{y}} \\left( P(\\hat{y}| x) \\right) \\\\\n",
    "\\end{align}\n",
    "\n",
    "This is called the maximum a posteriori principle (MAP https://de.wikipedia.org/wiki/Maximum_a_posteriori)\n",
    "\n",
    "\n",
    "Keep in mind that $x$ is a vector of $p$ observables. \n",
    "\n",
    "$$\n",
    "P(\\hat{y} | x^{(1)}, \\ldots, x^{(p)}) \n",
    "$$\n",
    "\n",
    "Using Bayes' theorem (https://en.wikipedia.org/wiki/Bayes'_theorem) for conditional probabilities we get \n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "f_{*} =& \\arg \\min_{\\hat{y}}\\left( P(\\hat{y} |x^{(1)}, \\ldots, x^{(p)})  \\right) \\\\\n",
    " =& \\arg \\min_{\\hat{y}}\\left(\\frac{P(\\hat{y}) \\cdot P(x^{(1)}, \\ldots, x^{(p)} | \\hat{y})} {P(x^{(1)}, \\ldots, x^{(p)})} \\right) \\\\\n",
    "  =& \\arg \\min_{\\hat{y}}\\left(P(\\hat{y}) \\cdot P(x^{(1)}, \\ldots, x^{(p)} | \\hat{y}) \\right) \\\\\n",
    "\\end{align}\n",
    "\n",
    "The problem is that usually the a priori distributions (aka the prior) is unknown and has to be appriximated using strong assumptions.\n",
    "\n",
    "The __Naive Bayes__ classifier does exactly that. Let's assume that the features are completely independent of each other. In that case we can write \n",
    "\n",
    "$$\n",
    "P(x^{(1)}, \\ldots, x^{(p)} | \\hat{y}) = \\prod^{p}_{i=1} P(x^{(i)}| \\hat{y})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "f_{*} = \\arg \\min_{\\hat{y}}\\left( P(\\hat{y}) \\prod^{p}_{i=1} P(x^{(i)}| \\hat{y})  \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "When $Y$ takes finite values (or classes) $Y = \\{Y_1, \\ldots Y_K\\}$, like in the Titanic dataset, we get the decission function for the Naive Bayes classifier \n",
    "\n",
    "$$\n",
    "y_{\\text{Naive Bayes}} = \\arg \\min_{k \\in {1, \\ldots, K}}\\left( P(Y_k) \\prod^{p}_{i=1} P(x^{(i)}| Y_k)  \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Note that the independency assumption is a very strong constraint. Features in real data are almost never independent of each other. __This assumption is almost always wrong__. (Hastie does call it the *idiots* classifier). \n",
    "\n",
    "Even under that assumption the probabilities $P(x^{(i)}| \\hat{y})$ are often not known. They can however often be approximated.\n",
    "\n",
    "In the Titanic dataset we simply assume uniform priors. That means $P(Y={\\text{Survived}}) = \\frac{\\text{number of passengers that survived}}{\\text{total number of passengers}}$.\n",
    "\n",
    "\n",
    "For the feature distributions/likelihoods we assume a Gaussian distribution. For a feature $\\mathbf{x_i}$, for example the age of a passenger, we assume a Gaussian distributions and empirically estimate both mean $\\mu_k$ and standard deviation $\\sigma_k$ of the samples of passengers in class $Y_k$. For a given value of an observable $v$, e.g. the age of a single passenger, we then compute \n",
    "\n",
    "$$\n",
    "p(x=v \\, | \\, Y_k) = \\mathcal{N}(\\mu_k, \\sigma_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
